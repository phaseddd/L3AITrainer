# 实操题2教学指南 - 智能训练（邮件分类）

## 📚 题目概述

这是一道**机器学习文本分类**题目，要求你构建一个邮件垃圾分类系统。整个流程分为三个步骤：
1. **数据预处理和划分** (2-1)
2. **模型训练** (2-2) 
3. **模型测试和评估** (2-3)

## 🎯 核心知识点（Java开发者视角）

### 1. Python vs Java 对比理解

| 概念 | Java | Python |
|------|------|--------|
| 导入库 | `import java.util.*` | `import pandas as pd` |
| 列表/数组 | `List<String> list = new ArrayList<>()` | `texts = data['text'].tolist()` |
| 字符串处理 | `text.toLowerCase().replaceAll()` | `text.lower()`, `re.sub()` |
| 文件操作 | `FileWriter`, `BufferedReader` | `pd.read_csv()`, `to_csv()` |
| 循环 | `for(String item : list)` | `for item in list:` |

### 2. 关键Python库理解

```python
# 数据处理 - 相当于Java的数据库操作
import pandas as pd          # 类似于Java的ResultSet，处理表格数据

# 文本处理 - 相当于Java的String工具类
import re                    # 正则表达式，类似Java的Pattern

# 机器学习 - 这是Python独有的优势
from sklearn.model_selection import train_test_split  # 数据划分
from transformers import AlbertTokenizer              # 文本分词器
```

## 📝 三个步骤详细解析

### 步骤1: 数据预处理 (2-1划分数据.py)

**目标**: 清洗数据并按7:3划分训练集和测试集

#### 🔍 关键代码分析

```python
# 1. 读取CSV文件 (类似Java的文件读取)
data = pd.read_csv("邮件数据.csv")  # 需要填入正确路径

# 2. 文本清洗函数 (类似Java的字符串处理方法)
def clean_text(text):
    text = re.sub(r'[^\w\s]', '', text)  # 去除特殊符号
    text = text.lower()                   # 转小写
    # 去除停用词 (the, a, an等无意义词汇)
    text = ' '.join([word for word in text.split() 
                    if word not in stopwords.words('english')])
    return text

# 3. 应用清洗函数到所有文本
data['text'] = data['text'].apply(clean_text)

# 4. 数据划分 (7:3比例)
train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)

# 5. 保存文件
os.makedirs("C:/Project/2/", exist_ok=True)  # 创建目录
train_data.to_csv("C:/Project/2/清洗后邮件数据_train.csv", index=False)
test_data.to_csv("C:/Project/2/清洗后邮件数据_test.csv", index=False)
```

#### ⚠️ 考试时需要注意的填空点：
1. CSV文件路径
2. 保存目录路径
3. 保存文件的完整路径

### 步骤2: 模型训练 (2-2训练模型.py)

**目标**: 使用BERT模型训练邮件分类器

#### 🧠 核心概念理解

**BERT模型**: 类似于一个"超级聪明的阅读理解AI"，能理解文本含义
- **Tokenizer**: 把文本切分成模型能理解的小块（类似Java的split()）
- **Model**: 实际的AI大脑，进行分类判断

#### 🔍 关键代码结构

```python
# 1. 自定义数据集类 (类似Java的数据封装类)
class TextDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_len):
        # 构造函数，类似Java的constructor
        
    def __getitem__(self, idx):
        # 获取单个数据项，类似Java的getter方法
        # 这里进行文本编码，把文字转换为数字
```

```python
# 2. 模型初始化
tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')
model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)

# 3. 训练循环 (类似Java的for循环处理)
for epoch in range(4):  # 训练4轮
    for batch in dataloader:  # 每批次数据
        # 前向传播 -> 计算损失 -> 反向传播 -> 更新参数
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
```

#### ⚠️ 考试重点参数：
- 学习率: `1e-5`
- 批次大小: `10`
- 训练轮数: `4`
- 优化器: `AdamW`

### 步骤3: 模型测试 (2-3测试模型效果.py)

**目标**: 加载训练好的模型，在测试集上评估性能

#### 📊 评估指标理解

```python
# 四个关键指标 (类似Java中的性能统计)
accuracy = accuracy_score(true_labels, predictions)    # 准确率：预测对的比例
precision = precision_score(true_labels, predictions)  # 精确率：预测为垃圾邮件中真正是垃圾邮件的比例  
recall = recall_score(true_labels, predictions)        # 召回率：所有垃圾邮件中被正确识别的比例
f1 = f1_score(true_labels, predictions)               # F1分数：精确率和召回率的调和平均
```

#### 🔍 关键代码流程

```python
# 1. 加载训练好的模型
model.load_state_dict(torch.load("C:/Project/2/2-2model_test.bin"))

# 2. 读取测试数据
test_data = pd.read_csv("C:/Project/2/清洗后邮件数据_test.csv")

# 3. 预测循环
with torch.no_grad():  # 不计算梯度，节省内存
    for batch in test_dataloader:
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)  # 获取预测结果

# 4. 保存结果到文件
with open('C:/Project/2/model_test_result.txt', 'w') as f:
    f.write(f"Accuracy: {accuracy}\n")
    # ... 其他指标
```

## 🚀 快速应试策略

### 1. 考试时的填空重点

**2-1文件需要填的空：**
- 数据文件路径: `"资源包路径/邮件数据.csv"`
- 保存目录: `"C:/Project/2/"`
- 训练集路径: `"C:/Project/2/清洗后邮件数据_train.csv"`
- 测试集路径: `"C:/Project/2/清洗后邮件数据_test.csv"`

**2-3文件需要填的空：**
- 模型路径: `"C:/Project/2/2-2model_test.bin"`
- 测试数据路径: `"C:/Project/2/清洗后邮件数据_test.csv"`
- 结果保存路径: `"C:/Project/2/model_test_result.txt"`

### 2. 记忆要点

```python
# 数据划分比例
train_test_split(data, test_size=0.3, random_state=42)  # 7:3划分

# 训练参数
lr=1e-5          # 学习率
batch_size=10    # 批次大小  
epochs=4         # 训练轮数
optimizer=AdamW  # 优化器

# 模型相关
'albert-base-v2'  # 预训练模型名称
num_labels=2      # 分类数量（垃圾/正常）
max_len=128       # 文本最大长度
```

### 3. 常见错误避免

1. **路径错误**: 确保所有文件路径使用正确的分隔符 `/` 或 `\\`
2. **目录不存在**: 使用 `os.makedirs()` 创建目录
3. **模型名称**: 题目可能把 `DistilBert` 改成 `Albert`，注意对应修改
4. **参数不匹配**: 严格按照题目要求设置超参数

## 💡 Java开发者的Python速成技巧

### 1. 语法对照
```python
# Python没有大括号，用缩进表示代码块
if condition:
    do_something()
    
# 列表推导式 (类似Java 8的Stream)
cleaned = [clean_text(text) for text in texts]

# 字典 (类似Java的Map)
config = {'lr': 1e-5, 'batch_size': 10}
```

### 2. 调试技巧
```python
print(f"数据形状: {data.shape}")        # 查看数据维度
print(f"标签分布: {data['label'].value_counts()}")  # 查看标签分布
print(f"训练进度: epoch {epoch}")       # 训练进度
```

## 🎯 考试当天建议

1. **先通读代码**: 理解整体流程，找出需要填空的地方
2. **按顺序完成**: 严格按照2-1 -> 2-2 -> 2-3的顺序
3. **检查路径**: 确保所有文件路径正确且目录存在
4. **运行测试**: 每完成一步都运行一下，确保没有错误
5. **保存备份**: 及时保存代码，避免意外丢失

记住：这道题的核心是**文本分类的机器学习流程**，理解了流程，填空就很简单了！

---

**祝你考试顺利！有任何问题随时问我。** 🎉